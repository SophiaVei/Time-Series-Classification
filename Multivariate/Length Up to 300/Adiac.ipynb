{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-14T15:15:21.737815700Z",
     "start_time": "2024-01-14T15:15:09.110284300Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "from tslearn.preprocessing import TimeSeriesScalerMinMax\n",
    "from sktime.datasets import load_UCR_UEA_dataset\n",
    "from sklearn.metrics import precision_score, f1_score, roc_auc_score\n",
    "import time\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from collections import Counter\n",
    "from memory_profiler import memory_usage\n",
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Deep Learning:\n",
    "from aeon.classification.deep_learning.mlp import MLPClassifier\n",
    "from aeon.classification.deep_learning.cnn import CNNClassifier\n",
    "from aeon.classification.deep_learning.fcn import FCNClassifier\n",
    "from sktime.classification.deep_learning.mcdcnn import MCDCNNClassifier\n",
    "\n",
    "# Dictionary-based:\n",
    "from aeon.classification.dictionary_based import (TemporalDictionaryEnsemble, IndividualTDE, MUSE)\n",
    "\n",
    "# Distance-based:\n",
    "from aeon.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "\n",
    "# Feature-based:\n",
    "from aeon.classification.feature_based import Catch22Classifier, FreshPRINCEClassifier\n",
    "\n",
    "# Interval-based\n",
    "from aeon.classification.interval_based import (CanonicalIntervalForestClassifier, DrCIFClassifier,\n",
    "                                                SupervisedTimeSeriesForest, TimeSeriesForestClassifier)\n",
    "\n",
    "# Kernel-based:\n",
    "from aeon.classification.convolution_based import RocketClassifier, Arsenal"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T15:15:25.198752400Z",
     "start_time": "2024-01-14T15:15:21.745817800Z"
    }
   },
   "id": "4f93683b33667a76"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of each time series: 176\n",
      "Train size: 390\n",
      "Test size: 391\n",
      "Training set class distribution: Counter({'24': 15, '4': 14, '19': 14, '28': 13, '1': 13, '25': 13, '8': 13, '33': 13, '32': 13, '27': 13, '30': 13, '15': 12, '12': 12, '6': 12, '36': 11, '17': 11, '10': 11, '14': 11, '22': 10, '2': 10, '11': 10, '7': 10, '16': 10, '35': 10, '18': 9, '29': 9, '26': 9, '9': 9, '23': 9, '34': 9, '20': 9, '31': 9, '21': 8, '37': 8, '13': 6, '3': 5, '5': 4})\n",
      "Test set class distribution: Counter({'25': 16, '5': 16, '3': 15, '36': 14, '12': 14, '13': 14, '2': 13, '18': 13, '37': 12, '21': 12, '20': 12, '8': 12, '19': 12, '34': 11, '31': 11, '26': 11, '29': 11, '23': 11, '9': 11, '16': 10, '22': 10, '35': 10, '7': 10, '11': 10, '14': 9, '10': 9, '15': 9, '17': 9, '24': 8, '6': 8, '30': 7, '32': 7, '28': 7, '27': 7, '1': 7, '33': 7, '4': 6})\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"Adiac\"  # Change this to match your dataset name\n",
    "\n",
    "# Load the dataset\n",
    "X_train_raw, y_train = load_UCR_UEA_dataset(\"Adiac\", split=\"train\", return_X_y=True)\n",
    "X_test_raw, y_test = load_UCR_UEA_dataset(\"Adiac\", split=\"test\", return_X_y=True)\n",
    "\n",
    "# Print dataset sizes and class distribution\n",
    "print(\"Length of each time series:\", X_train_raw.iloc[0, 0].size)\n",
    "print(\"Train size:\", len(y_train))\n",
    "print(\"Test size:\", len(y_test))\n",
    "print(\"Training set class distribution:\", Counter(y_train))\n",
    "print(\"Test set class distribution:\", Counter(y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T18:21:09.134632400Z",
     "start_time": "2024-01-14T18:21:07.447835100Z"
    }
   },
   "id": "192ac8fbf3974752"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# Function to convert DataFrame to 3D numpy array (for multivariate time series)\n",
    "def dataframe_to_3darray(df):\n",
    "    num_samples = df.shape[0]\n",
    "    num_channels = df.shape[1]\n",
    "    num_timesteps = df.iloc[0, 0].shape[0]\n",
    "    array_3d = np.empty((num_samples, num_channels, num_timesteps))\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        for c in range(num_channels):\n",
    "            array_3d[i, c, :] = df.iloc[i, c]\n",
    "\n",
    "    return array_3d"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T18:21:09.150631800Z",
     "start_time": "2024-01-14T18:21:09.113631Z"
    }
   },
   "id": "1d0dfc3d495d5c9"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# Convert and preprocess the data (maintaining multivariate structure)\n",
    "scaler = TimeSeriesScalerMinMax()\n",
    "X_train_processed = scaler.fit_transform(dataframe_to_3darray(X_train_raw))\n",
    "X_test_processed = scaler.transform(dataframe_to_3darray(X_test_raw))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T18:21:10.604421400Z",
     "start_time": "2024-01-14T18:21:09.143633700Z"
    }
   },
   "id": "6e80ecd1d091b64"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# Define a list of classifiers\n",
    "classifiers = [MLPClassifier(),\n",
    "               CNNClassifier(),\n",
    "               FCNClassifier(),\n",
    "               MCDCNNClassifier(),\n",
    "               TemporalDictionaryEnsemble(),\n",
    "               IndividualTDE(),\n",
    "               MUSE(support_probabilities=True),\n",
    "               KNeighborsTimeSeriesClassifier(),\n",
    "               Catch22Classifier(),\n",
    "               FreshPRINCEClassifier(),\n",
    "               SupervisedTimeSeriesForest(),\n",
    "               TimeSeriesForestClassifier(),\n",
    "               CanonicalIntervalForestClassifier(),\n",
    "               DrCIFClassifier(),\n",
    "               RocketClassifier(),\n",
    "               Arsenal()]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T18:21:10.670948500Z",
     "start_time": "2024-01-14T18:21:10.594418900Z"
    }
   },
   "id": "69bbfb6c57ae7da7"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# Initialize lists to store results\n",
    "results = {\"Classifier\": [], \"Execution Time\": [], \"Memory Usage\": [], \"Precision\": [], \"Accuracy\": [],\n",
    "           \"F1 Score\": [], \"ROC-AUC Score (Macro)\": [], \"ROC-AUC Score (Micro)\": [], \"Confusion Matrix\": []}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T18:21:10.691951400Z",
     "start_time": "2024-01-14T18:21:10.661947Z"
    }
   },
   "id": "a2055b0901ca2a6f"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# Function to evaluate classifier\n",
    "def evaluate_classifier(classifier, X_train, X_test, y_train, y_test):\n",
    "    # Inner function to include both fitting and prediction for memory profiling\n",
    "    def fit_and_predict():\n",
    "        classifier.fit(X_train, y_train)\n",
    "        return classifier.predict(X_test)\n",
    "\n",
    "    # Measure execution time and memory usage for fitting and predicting\n",
    "    start_time = time.time()\n",
    "    mem_usage = memory_usage((fit_and_predict,), interval=0.1, include_children=True, retval=True)\n",
    "    execution_time = time.time() - start_time\n",
    "    max_mem_usage = max(mem_usage[0]) - min(mem_usage[0])  # mem_usage[0] contains the memory usage\n",
    "    predicted_labels = mem_usage[1]  # mem_usage[1] contains the return value from fit_and_predict\n",
    "\n",
    "    # Proceed with the rest of the evaluation\n",
    "    precision = precision_score(y_test, predicted_labels, average='weighted')\n",
    "    accuracy = accuracy_score(y_test, predicted_labels)\n",
    "    f1_score_val = f1_score(y_test, predicted_labels, average='weighted')\n",
    "    confusion = confusion_matrix(y_test, predicted_labels)\n",
    "\n",
    "    # If the classifier supports probability estimates, calculate ROC AUC scores\n",
    "    roc_auc_macro = roc_auc_micro = None\n",
    "    if hasattr(classifier, \"predict_proba\"):\n",
    "        y_prob = classifier.predict_proba(X_test)\n",
    "        roc_auc_macro = roc_auc_score(y_test, y_prob, multi_class='ovr', average='macro')\n",
    "        roc_auc_micro = roc_auc_score(y_test, y_prob, multi_class='ovr', average='micro')\n",
    "\n",
    "    # Return all the metrics including memory usage\n",
    "    return execution_time, max_mem_usage, precision, accuracy, f1_score_val, roc_auc_macro, roc_auc_micro, confusion"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T18:21:12.629972200Z",
     "start_time": "2024-01-14T18:21:12.598440500Z"
    }
   },
   "id": "9982b9692fc96739"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# Preparing to plot ROC-AUC curves\n",
    "fpr_dict = {}\n",
    "tpr_dict = {}\n",
    "roc_auc_dict = {}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T18:21:13.561062500Z",
     "start_time": "2024-01-14T18:21:13.525060400Z"
    }
   },
   "id": "41abf0ef7e8c9d5f"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sophi\\PycharmProjects\\TimeSeriesClassification\\venv\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sophi\\PycharmProjects\\TimeSeriesClassification\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[26], line 5\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m classifier \u001B[38;5;129;01min\u001B[39;00m classifiers:\n\u001B[0;32m      3\u001B[0m     classifier_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtype\u001B[39m(classifier)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\n\u001B[0;32m      4\u001B[0m     exec_time, max_mem_usage, precision, accuracy, f1_score_val, roc_auc_macro, roc_auc_micro, confusion \u001B[38;5;241m=\u001B[39m \\\n\u001B[1;32m----> 5\u001B[0m         \u001B[43mevaluate_classifier\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclassifier\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_train_processed\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_test_processed\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      8\u001B[0m     results[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mClassifier\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mappend(classifier_name)\n\u001B[0;32m      9\u001B[0m     results[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExecution Time\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mappend(exec_time)\n",
      "Cell \u001B[1;32mIn[24], line 10\u001B[0m, in \u001B[0;36mevaluate_classifier\u001B[1;34m(classifier, X_train, X_test, y_train, y_test)\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;66;03m# Measure execution time and memory usage for fitting and predicting\u001B[39;00m\n\u001B[0;32m      9\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m---> 10\u001B[0m mem_usage \u001B[38;5;241m=\u001B[39m \u001B[43mmemory_usage\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfit_and_predict\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minterval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minclude_children\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m     11\u001B[0m execution_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m start_time\n\u001B[0;32m     12\u001B[0m max_mem_usage \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmax\u001B[39m(mem_usage[\u001B[38;5;241m0\u001B[39m]) \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mmin\u001B[39m(mem_usage[\u001B[38;5;241m0\u001B[39m])  \u001B[38;5;66;03m# mem_usage[0] contains the memory usage\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\TimeSeriesClassification\\venv\\lib\\site-packages\\memory_profiler.py:379\u001B[0m, in \u001B[0;36mmemory_usage\u001B[1;34m(proc, interval, timeout, timestamps, include_children, multiprocess, max_usage, retval, stream, backend, max_iterations)\u001B[0m\n\u001B[0;32m    376\u001B[0m \u001B[38;5;66;03m# When there is an exception in the \"proc\" - the (spawned) monitoring processes don't get killed.\u001B[39;00m\n\u001B[0;32m    377\u001B[0m \u001B[38;5;66;03m# Therefore, the whole process hangs indefinitely. Here, we are ensuring that the process gets killed!\u001B[39;00m\n\u001B[0;32m    378\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 379\u001B[0m     returned \u001B[38;5;241m=\u001B[39m f(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw)\n\u001B[0;32m    380\u001B[0m     parent_conn\u001B[38;5;241m.\u001B[39msend(\u001B[38;5;241m0\u001B[39m)  \u001B[38;5;66;03m# finish timing\u001B[39;00m\n\u001B[0;32m    381\u001B[0m     ret \u001B[38;5;241m=\u001B[39m parent_conn\u001B[38;5;241m.\u001B[39mrecv()\n",
      "Cell \u001B[1;32mIn[24], line 5\u001B[0m, in \u001B[0;36mevaluate_classifier.<locals>.fit_and_predict\u001B[1;34m()\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit_and_predict\u001B[39m():\n\u001B[1;32m----> 5\u001B[0m     \u001B[43mclassifier\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m classifier\u001B[38;5;241m.\u001B[39mpredict(X_test)\n",
      "File \u001B[1;32m~\\PycharmProjects\\TimeSeriesClassification\\venv\\lib\\site-packages\\aeon\\classification\\base.py:157\u001B[0m, in \u001B[0;36mBaseClassifier.fit\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m    155\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_is_fitted \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    156\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n\u001B[1;32m--> 157\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    158\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfit_time_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(\u001B[38;5;28mround\u001B[39m(time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m1000\u001B[39m)) \u001B[38;5;241m-\u001B[39m start\n\u001B[0;32m    159\u001B[0m \u001B[38;5;66;03m# this should happen last\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\TimeSeriesClassification\\venv\\lib\\site-packages\\aeon\\classification\\deep_learning\\mlp.py:226\u001B[0m, in \u001B[0;36mMLPClassifier._fit\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m    207\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfile_name_ \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    208\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbest_file_name \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msave_best_model \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(time\u001B[38;5;241m.\u001B[39mtime_ns())\n\u001B[0;32m    209\u001B[0m )\n\u001B[0;32m    211\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallbacks_ \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    212\u001B[0m     [\n\u001B[0;32m    213\u001B[0m         tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mcallbacks\u001B[38;5;241m.\u001B[39mReduceLROnPlateau(\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    223\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallbacks\n\u001B[0;32m    224\u001B[0m )\n\u001B[1;32m--> 226\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhistory \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining_model_\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    227\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    228\u001B[0m \u001B[43m    \u001B[49m\u001B[43my_onehot\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    229\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    230\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_epochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    231\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    232\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcallbacks_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    233\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    235\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    236\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_ \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mmodels\u001B[38;5;241m.\u001B[39mload_model(\n\u001B[0;32m    237\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfile_path \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfile_name_ \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.hdf5\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mcompile\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m    238\u001B[0m     )\n",
      "File \u001B[1;32m~\\PycharmProjects\\TimeSeriesClassification\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\PycharmProjects\\TimeSeriesClassification\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py:1783\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1775\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[0;32m   1776\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1777\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1780\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[0;32m   1781\u001B[0m ):\n\u001B[0;32m   1782\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[1;32m-> 1783\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1784\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   1785\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32m~\\PycharmProjects\\TimeSeriesClassification\\venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\PycharmProjects\\TimeSeriesClassification\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:831\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    828\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    830\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 831\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    833\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    834\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32m~\\PycharmProjects\\TimeSeriesClassification\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:867\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    864\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    865\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[0;32m    866\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[1;32m--> 867\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtracing_compilation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    868\u001B[0m \u001B[43m      \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_no_variable_creation_config\u001B[49m\n\u001B[0;32m    869\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    870\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_config \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    871\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[0;32m    872\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[0;32m    873\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[1;32m~\\PycharmProjects\\TimeSeriesClassification\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001B[0m, in \u001B[0;36mcall_function\u001B[1;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[0;32m    137\u001B[0m bound_args \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    138\u001B[0m flat_inputs \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39munpack_inputs(bound_args)\n\u001B[1;32m--> 139\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[0;32m    140\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflat_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\n\u001B[0;32m    141\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\TimeSeriesClassification\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1264\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, tensor_inputs, captured_inputs)\u001B[0m\n\u001B[0;32m   1260\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1261\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1262\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1263\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1264\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1265\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1266\u001B[0m     args,\n\u001B[0;32m   1267\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1268\u001B[0m     executing_eagerly)\n\u001B[0;32m   1269\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32m~\\PycharmProjects\\TimeSeriesClassification\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:217\u001B[0m, in \u001B[0;36mAtomicFunction.flat_call\u001B[1;34m(self, args)\u001B[0m\n\u001B[0;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mflat_call\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core\u001B[38;5;241m.\u001B[39mTensor]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[0;32m    216\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 217\u001B[0m   flat_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    218\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mpack_output(flat_outputs)\n",
      "File \u001B[1;32m~\\PycharmProjects\\TimeSeriesClassification\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:252\u001B[0m, in \u001B[0;36mAtomicFunction.__call__\u001B[1;34m(self, *args)\u001B[0m\n\u001B[0;32m    250\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[0;32m    251\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[1;32m--> 252\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_bound_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    253\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    254\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    255\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    256\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    257\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    258\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\n\u001B[0;32m    259\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    260\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[0;32m    261\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mfunction_call_options\u001B[38;5;241m.\u001B[39mas_attrs(),\n\u001B[0;32m    262\u001B[0m     )\n",
      "File \u001B[1;32m~\\PycharmProjects\\TimeSeriesClassification\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1479\u001B[0m, in \u001B[0;36mContext.call_function\u001B[1;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[0;32m   1477\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[0;32m   1478\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1479\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1480\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1481\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1482\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1483\u001B[0m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1484\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1485\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1486\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1487\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m   1488\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m   1489\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1493\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[0;32m   1494\u001B[0m   )\n",
      "File \u001B[1;32m~\\PycharmProjects\\TimeSeriesClassification\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:60\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     53\u001B[0m   \u001B[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001B[39;00m\n\u001B[0;32m     54\u001B[0m   inputs \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m     55\u001B[0m       tensor_conversion_registry\u001B[38;5;241m.\u001B[39mconvert(t)\n\u001B[0;32m     56\u001B[0m       \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(t, core_types\u001B[38;5;241m.\u001B[39mTensor)\n\u001B[0;32m     57\u001B[0m       \u001B[38;5;28;01melse\u001B[39;00m t\n\u001B[0;32m     58\u001B[0m       \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m inputs\n\u001B[0;32m     59\u001B[0m   ]\n\u001B[1;32m---> 60\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     61\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     62\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     63\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Evaluate each classifier\n",
    "for classifier in classifiers:\n",
    "    classifier_name = type(classifier).__name__\n",
    "    exec_time, max_mem_usage, precision, accuracy, f1_score_val, roc_auc_macro, roc_auc_micro, confusion = \\\n",
    "        evaluate_classifier(classifier, X_train_processed, X_test_processed, y_train, y_test)\n",
    "\n",
    "\n",
    "    results[\"Classifier\"].append(classifier_name)\n",
    "    results[\"Execution Time\"].append(exec_time)\n",
    "    results[\"Memory Usage\"].append(max_mem_usage)\n",
    "    results[\"Precision\"].append(precision)\n",
    "    results[\"Accuracy\"].append(accuracy)\n",
    "    results[\"F1 Score\"].append(f1_score_val)\n",
    "    results[\"ROC-AUC Score (Macro)\"].append(roc_auc_macro)\n",
    "    results[\"ROC-AUC Score (Micro)\"].append(roc_auc_micro)\n",
    "    results[\"Confusion Matrix\"].append(confusion)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"{classifier_name} Execution Time: {exec_time:.2f}s\")\n",
    "    print(f\"{classifier_name} Memory Usage: {max_mem_usage:.2f} MB\")\n",
    "    print(f\"{classifier_name} Precision: {precision:.2f}\")\n",
    "    print(f\"{classifier_name} Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"{classifier_name} F1 Score: {f1_score_val:.2f}\")\n",
    "    print(f\"{classifier_name} ROC-AUC Score (Macro): {roc_auc_macro:.2f}\")\n",
    "    print(f\"{classifier_name} ROC-AUC Score (Micro): {roc_auc_micro:.2f}\")\n",
    "\n",
    "\n",
    "    if hasattr(classifier, \"predict_proba\"):\n",
    "        y_prob = classifier.predict_proba(X_test_processed)\n",
    "        y_test_bin = label_binarize(y_test, classes=np.unique(y_train))\n",
    "        n_classes = y_test_bin.shape[1]\n",
    "\n",
    "        fpr = dict()\n",
    "        tpr = dict()\n",
    "        roc_auc = dict()\n",
    "        for i in range(n_classes):\n",
    "            fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_prob[:, i])\n",
    "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "        fpr_dict[classifier_name] = fpr\n",
    "        tpr_dict[classifier_name] = tpr\n",
    "        roc_auc_dict[classifier_name] = roc_auc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T18:33:41.993509600Z",
     "start_time": "2024-01-14T18:21:13.920167400Z"
    }
   },
   "id": "975378cd3edaed22"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot ROC-AUC Curves\n",
    "\n",
    "# Define the number of columns and rows you want\n",
    "num_cols = 4  # Fewer columns\n",
    "num_rows = 6  # More rows to accommodate all classifiers, assuming 21 classifiers\n",
    "\n",
    "# Calculate figure size dynamically based on the number of columns and rows\n",
    "# Each subplot will be of size (4, 4) for example, but you can adjust this as needed\n",
    "subplot_size_width = 4\n",
    "subplot_size_height = 4\n",
    "fig_width = subplot_size_width * num_cols\n",
    "fig_height = subplot_size_height * num_rows\n",
    "\n",
    "# Initialize the figure with the calculated dimensions\n",
    "plt.figure(figsize=(fig_width, fig_height))\n",
    "\n",
    "# Create the ROC AUC plots\n",
    "for i, classifier_name in enumerate(results[\"Classifier\"]):\n",
    "    ax = plt.subplot(num_rows, num_cols, i + 1)\n",
    "    for j in range(n_classes):\n",
    "        ax.plot(fpr_dict[classifier_name][j], tpr_dict[classifier_name][j], lw=2,\n",
    "                label=f'Class {j} (AUC = {roc_auc_dict[classifier_name][j]:.2f})')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title(f'ROC AUC for {classifier_name}')\n",
    "    ax.legend(loc=\"lower right\")\n",
    "\n",
    "# Adjust the spacing between subplots and the top edge of the figure\n",
    "plt.subplots_adjust(hspace=0.3, wspace=0.3, top=0.9)\n",
    "\n",
    "# Add an overall title\n",
    "plt.suptitle(f'{dataset_name} ROC AUC Curves', fontsize=20, y=0.98)\n",
    "\n",
    "# Save the figure with enough room for the suptitle\n",
    "plt.tight_layout()  # This adjusts subplot params so that the subplots fit into the figure area.\n",
    "plt.subplots_adjust(top=0.95)  # Adjust this value to increase the space for the title.\n",
    "plt.suptitle(f\"{dataset_name} ROC AUC Curves\", fontsize=16)\n",
    "plt.savefig(f\"{dataset_name}_ROC_AUC_curves.png\", bbox_inches='tight')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T17:58:58.714755100Z",
     "start_time": "2024-01-14T17:58:58.636225200Z"
    }
   },
   "id": "ff2afc6b1fbdbe27"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_roc_auc_curves_macro(fpr_dict, tpr_dict, roc_auc_dict, classifiers, n_classes, dataset_name=dataset_name):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    colors = cycle(['blue', 'red', 'green', 'purple', 'orange', 'brown', 'pink', 'gray', 'olive', 'cyan'])\n",
    "    \n",
    "    colors = cycle(['midnightblue', 'indianred', 'green', 'purple', 'orange', 'brown', 'pink', 'gray', 'olive', 'cyan', 'mediumaquamarine', 'chocolate', 'palegreen', 'antiquewhite', 'tan', 'darkseagreen'])\n",
    "\n",
    "    for (classifier_name, color) in zip(classifiers, colors):\n",
    "        fpr = fpr_dict[classifier_name]\n",
    "        tpr = tpr_dict[classifier_name]\n",
    "        roc_auc = roc_auc_dict[classifier_name]\n",
    "\n",
    "        all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "        mean_tpr = np.zeros_like(all_fpr)\n",
    "        for i in range(n_classes):\n",
    "            mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])  # Use np.interp instead of interp\n",
    "        mean_tpr /= n_classes\n",
    "\n",
    "        fpr[\"macro\"] = all_fpr\n",
    "        tpr[\"macro\"] = mean_tpr\n",
    "        roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "        plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "                 label=f'macro-average ROC curve of {classifier_name} (area = {roc_auc[\"macro\"]:.2f})',\n",
    "                 color=color, linestyle='-', linewidth=2)\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'{dataset_name} Macro-average ROC curve per classifier')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the figure with the dataset name in the filename\n",
    "    filename = f\"{dataset_name}_macro_average_roc_curve.png\"\n",
    "    plt.savefig(filename)\n",
    "    plt.show()\n",
    "    plt.close()  # Close the figure to free memory\n",
    "\n",
    "# Call the function with the appropriate parameters\n",
    "plot_roc_auc_curves_macro(fpr_dict, tpr_dict, roc_auc_dict, results[\"Classifier\"], n_classes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-14T17:58:58.642223600Z"
    }
   },
   "id": "46d98074b37ec8e3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Function to plot results\n",
    "def plot_results(results, metric, title, color):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(results[\"Classifier\"], results[metric], color=color)\n",
    "    plt.xlabel('Classifiers')\n",
    "    plt.ylabel(metric)\n",
    "    plt.title(title)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.xticks(rotation=90, ha='right')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_results_improved(results, metric, dataset_name, color, ylabel=None):\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.bar(results[\"Classifier\"], results[metric], color=color)\n",
    "    plt.xlabel('Classifiers')\n",
    "    if ylabel:\n",
    "        plt.ylabel(ylabel)\n",
    "    title = f\"{dataset_name} {metric} Comparison\"\n",
    "    plt.title(title)\n",
    "    if metric == \"Execution Time\":\n",
    "        max_execution_time = max(results[metric])\n",
    "        plt.ylim(0, max_execution_time * 1.1)\n",
    "    else:\n",
    "        plt.ylim(0, max(results[metric]) * 1.1)  # Adjust for other metrics as well\n",
    "\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    # Save the figure\n",
    "    plt.savefig(f\"{dataset_name}_{metric}.png\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Apply the improved plotting function for each metric you want to plot\n",
    "plot_results_improved(results, \"Accuracy\", dataset_name, \"chocolate\")\n",
    "plot_results_improved(results, \"ROC-AUC Score (Macro)\", dataset_name, \"saddlebrown\")\n",
    "plot_results_improved(results, \"Execution Time\", dataset_name, \"sandybrown\", ylabel=\"Time (s)\")\n",
    "plot_results_improved(results, \"Memory Usage\", dataset_name, \"peachpuff\", ylabel=\"Space (MB)\")\n",
    "plot_results_improved(results, \"Precision\", dataset_name, \"peru\")\n",
    "plot_results_improved(results, \"F1 Score\", dataset_name, \"sienna\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92742ef87424ab55"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot confusion matrices together\n",
    "num_classifiers = len(results[\"Classifier\"])\n",
    "num_cols = 6\n",
    "num_rows = -(-num_classifiers // num_cols)  # Ceiling division\n",
    "\n",
    "plt.figure(figsize=(20, 4 * num_rows))\n",
    "for i, classifier_name in enumerate(results[\"Classifier\"]):\n",
    "    plt.subplot(num_rows, num_cols, i + 1)\n",
    "    plt.imshow(results[\"Confusion Matrix\"][i], interpolation='nearest', cmap=plt.cm.Oranges)\n",
    "    plt.title(f'{classifier_name}')\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    tick_marks = np.arange(len(np.unique(y_train)))\n",
    "    plt.xticks(tick_marks, tick_marks, rotation=45)\n",
    "    plt.yticks(tick_marks, tick_marks)\n",
    "\n",
    "# Adjust the spacing of the subplots to make room for the suptitle\n",
    "plt.subplots_adjust(top=0.85)  # You may need to adjust this value\n",
    "plt.suptitle(f\"{dataset_name} Confusion Matrices\", fontsize=16)\n",
    "\n",
    "# Save the figure with enough room for the suptitle\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # You may need to adjust these values\n",
    "plt.savefig(f\"{dataset_name}_Confusion_Matrices.png\", bbox_inches='tight')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df7658833f528e03"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
